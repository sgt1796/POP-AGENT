{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38dcf8ef",
   "metadata": {},
   "source": [
    "# agent.py Interactive Tutorial\n",
    "\n",
    "This notebook walks through the `Agent` class in `agent.py`. The content is adapted from `walkthrou.md` and checked against the actual code so the explanations stay accurate. Code cells are runnable without POP by using a small mock LLM stream.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc3853d3",
   "metadata": {},
   "source": [
    "## High-level purpose\n",
    "\n",
    "`agent.py` defines `Agent`, a stateful conversation orchestrator that:\n",
    "- Owns conversation state (system prompt, model, messages, tools, streaming flags).\n",
    "- Exposes high-level APIs to `prompt`, `continue_run`, `steer`, and `follow_up`.\n",
    "- Bridges your app or UI to the low-level event loop in `agent_loop.py`.\n",
    "- Lets you subscribe to events like message streaming and tool execution.\n",
    "\n",
    "Think of `Agent` as the facade and state container, and `agent_loop.py` as the engine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4749a2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01masyncio\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m      6\u001b[39m     AgentEvent,\n\u001b[32m      7\u001b[39m     AgentMessage,\n\u001b[32m   (...)\u001b[39m\u001b[32m     12\u001b[39m     ThinkingLevel,\n\u001b[32m     13\u001b[39m )\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\sgt17\\OneDrive\\Desktop\\POP\\agent\\agent.py:17\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Awaitable, Callable, Dict, Iterable, List, Optional, Sequence, Tuple, Union\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent_loop\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AgentLoopConfig, agent_loop, agent_loop_continue\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevent_stream\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m EventStream\n\u001b[32m     19\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01magent_types\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     20\u001b[39m     AgentContext,\n\u001b[32m     21\u001b[39m     AgentEvent,\n\u001b[32m   (...)\u001b[39m\u001b[32m     28\u001b[39m     ImageContent,\n\u001b[32m     29\u001b[39m )\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "\n",
    "from agent import Agent\n",
    "from agent.agent_types import (\n",
    "    AgentEvent,\n",
    "    AgentMessage,\n",
    "    AgentTool,\n",
    "    AgentToolResult,\n",
    "    ImageContent,\n",
    "    TextContent,\n",
    "    ThinkingLevel,\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e8e979",
   "metadata": {},
   "source": [
    "## Dependencies and POP defaults\n",
    "\n",
    "`Agent` depends on `agent_loop.agent_loop` and `agent_loop.agent_loop_continue`, uses `EventStream`, and imports types from `agent_types`.\n",
    "\n",
    "It tries to import POP to get defaults:\n",
    "- If POP is available, it calls `POP.get_model(\"google\", \"gemini-2.5-flash-lite-preview-06-17\")` for the default model.\n",
    "- If POP is missing, the default model is `{\"provider\": \"unknown\", \"id\": \"unknown\", \"api\": None}`.\n",
    "- If POP is missing and you do not supply a `stream_fn`, `Agent` sets `stream_fn = None` and raises later when you call `prompt` or `continue_run`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca465b06",
   "metadata": {},
   "source": [
    "## Default message conversion\n",
    "\n",
    "`_default_convert_to_llm` filters messages by role (`user`, `assistant`, `toolResult`) and converts them to dicts via `AgentMessage.to_dict()`.\n",
    "If conversion fails, it falls back to a best-effort dict with `role`, `content` (via `vars`), and `timestamp`.\n",
    "\n",
    "You can override this with `opts[\"convert_to_llm\"]` when constructing `Agent`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1368ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def convert_to_llm_minimal(messages):\n",
    "    # Minimal conversion that keeps only user, assistant, and toolResult roles.\n",
    "    llm_msgs = []\n",
    "    for m in messages:\n",
    "        if m.role not in {\"user\", \"assistant\", \"toolResult\"}:\n",
    "            continue\n",
    "        llm_msgs.append(m.to_dict())\n",
    "    return llm_msgs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e41d6d9",
   "metadata": {},
   "source": [
    "## Construction and options\n",
    "\n",
    "`Agent(opts=...)` accepts optional keys:\n",
    "- `initial_state`: override fields on `AgentState` (only known fields are applied).\n",
    "- `convert_to_llm`: custom message conversion function.\n",
    "- `transform_context`: optional pruning or augmentation before each LLM call.\n",
    "- `steering_mode`: `\"one-at-a-time\"` (default) or `\"all\"`.\n",
    "- `follow_up_mode`: `\"one-at-a-time\"` (default) or `\"all\"`.\n",
    "- `stream_fn`: LLM transport function (defaults to `POP.stream.stream` if available).\n",
    "- `session_id`: forwarded to the provider.\n",
    "- `get_api_key`: async hook to fetch an API key per call.\n",
    "- `thinking_budgets`: custom token budgets for reasoning.\n",
    "- `max_retry_delay_ms`: maximum backoff delay.\n",
    "\n",
    "The default `AgentState` includes:\n",
    "- `system_prompt`, `model`, `thinking_level`, `tools`, `messages`\n",
    "- `is_streaming`, `stream_message`\n",
    "- `pending_tool_calls`\n",
    "- `error`\n",
    "\n",
    "Also present in the public API (not just setters):\n",
    "- `get_steering_mode()` and `get_follow_up_mode()`\n",
    "- `continue_()` as an alias for `continue_run()`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f0720",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "attempted relative import with no known parent package",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpop\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mstream\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m stream\n\u001b[32m      3\u001b[39m agent = Agent(\n\u001b[32m      4\u001b[39m     opts={\n\u001b[32m      5\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mstream_fn\u001b[39m\u001b[33m\"\u001b[39m: stream,\n\u001b[32m   (...)\u001b[39m\u001b[32m     10\u001b[39m     }\n\u001b[32m     11\u001b[39m )\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m agent._state.\u001b[34m__dict__\u001b[39m.items():\n",
      "\u001b[31mImportError\u001b[39m: attempted relative import with no known parent package"
     ]
    }
   ],
   "source": [
    "from POP.stream import stream\n",
    "\n",
    "agent = Agent(\n",
    "    opts={\n",
    "        \"stream_fn\": stream,\n",
    "        \"initial_state\": {\n",
    "            \"system_prompt\": \"You are a helpful assistant.\"\n",
    "                    },\n",
    "        \"session_id\": \"demo-session\",\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "for k, v in agent._state.__dict__.items():\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1717de5",
   "metadata": {},
   "source": [
    "## State mutators and getters\n",
    "\n",
    "`agent.state` is read-only by convention; use setter methods instead:\n",
    "- `set_system_prompt`, `set_model`, `set_thinking_level`\n",
    "- `set_tools`, `replace_messages`, `append_message`\n",
    "- `set_steering_mode`, `get_steering_mode`\n",
    "- `set_follow_up_mode`, `get_follow_up_mode`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c32f267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('one-at-a-time', 'one-at-a-time')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.set_system_prompt(\"System prompt for this run.\")\n",
    "# agent.set_model({\"provider\": \"openai\", \"id\": \"gpt-5-nano\", \"api\": None})\n",
    "agent.set_model({\"provider\": \"openai\", \"id\": None, \"api\": None})\n",
    "agent.set_tools([])\n",
    "\n",
    "agent.get_steering_mode(), agent.get_follow_up_mode()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d825d3b0",
   "metadata": {},
   "source": [
    "## Queues: steering and follow-up\n",
    "\n",
    "- `steer(message)` queues a message that can be injected mid-turn by the loop.\n",
    "- `follow_up(message)` queues a message used when the agent would otherwise finish.\n",
    "- Modes control dequeue behavior: `\"one-at-a-time\"` or `\"all\"`.\n",
    "- Clearing helpers: `clear_steering_queue`, `clear_follow_up_queue`, `clear_all_queues`.\n",
    "- `clear_messages` removes conversation history but does not change tools or system prompt.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7ff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AgentState(system_prompt='System prompt for this run.', model={'provider': 'openai', 'id': None, 'api': None}, thinking_level='off', tools=[], messages=[], is_streaming=False, stream_message=None, pending_tool_calls=set(), error=None)\n",
      "system_prompt: System prompt for this run.\n",
      "model: {'provider': 'openai', 'id': None, 'api': None}\n",
      "thinking_level: off\n",
      "tools: []\n",
      "messages:\n",
      "is_streaming: False\n",
      "stream_message: None\n",
      "pending_tool_calls: set()\n",
      "error: None\n"
     ]
    }
   ],
   "source": [
    "msg = AgentMessage(\n",
    "    role=\"user\",\n",
    "    content=[TextContent(type=\"text\", text=\"Please be concise.\")],\n",
    "    timestamp=time.time(),\n",
    ")\n",
    "\n",
    "agent.steer(msg)\n",
    "agent.follow_up(msg)\n",
    "\n",
    "print(agent._state)\n",
    "\n",
    "\n",
    "agent.set_steering_mode(\"one-at-a-time\")\n",
    "agent.set_follow_up_mode(\"one-at-a-time\")\n",
    "\n",
    "for k, v in agent._state.__dict__.items():\n",
    "    if k == \"messages\":\n",
    "        print(f\"{k}:\")\n",
    "        for m in v:\n",
    "            print(f\"  - {m.role}: {[c.text for c in m.content if isinstance(c, TextContent)]}\")\n",
    "        continue\n",
    "    print(f\"{k}: {v}\")\n",
    "\n",
    "agent.clear_all_queues()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b21f00",
   "metadata": {},
   "source": [
    "## Event subscription and event flow\n",
    "\n",
    "`subscribe(fn)` registers a listener that receives every event emitted by the loop. Listeners run synchronously; exceptions are swallowed to avoid breaking the agent.\n",
    "\n",
    "Event types observed by `Agent` include:\n",
    "- `message_start`, `message_update`, `message_end`\n",
    "- `tool_execution_start`, `tool_execution_end`\n",
    "- `turn_end`, `agent_end`\n",
    "\n",
    "`Agent` tracks `pending_tool_calls` using `tool_execution_start/end` events, and updates `state.error` when a `turn_end` event contains an assistant error message.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a94af0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['agent_start',\n",
       " 'turn_start',\n",
       " 'message_start',\n",
       " 'message_end',\n",
       " 'message_start',\n",
       " 'message_update',\n",
       " 'message_update',\n",
       " 'message_update',\n",
       " 'message_end',\n",
       " 'turn_end',\n",
       " 'agent_end']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "events = []\n",
    "\n",
    "def on_event(e):\n",
    "    events.append(e.get(\"type\"))\n",
    "\n",
    "unsubscribe = agent.subscribe(on_event)\n",
    "\n",
    "# Jupyter supports top-level await.\n",
    "await agent.prompt(\"Hello\")\n",
    "\n",
    "unsubscribe()\n",
    "\n",
    "events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc218ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "system_prompt: System prompt for this run.\n",
      "model: {'provider': 'openai', 'id': None, 'api': None}\n",
      "thinking_level: off\n",
      "tools: []\n",
      "messages:\n",
      "  - user: ['Hello']\n",
      "  - assistant: ['Hello! How can I help you today? I can answer questions, brainstorm ideas, draft or edit text, help with coding or math, plan projects, or just chat. What would you like to do?']\n",
      "is_streaming: False\n",
      "stream_message: None\n",
      "pending_tool_calls: set()\n",
      "error: None\n"
     ]
    }
   ],
   "source": [
    "for k, v in agent._state.__dict__.items():\n",
    "    if k == \"messages\":\n",
    "        print(f\"{k}:\")\n",
    "        for m in v:\n",
    "            print(f\"  - {m.role}: {[c.text for c in m.content if isinstance(c, TextContent)]}\")\n",
    "        continue\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505d0f72",
   "metadata": {},
   "source": [
    "## prompt and continue_run\n",
    "\n",
    "`prompt(input, images=None)` accepts:\n",
    "- `str` (wrapped into a user `AgentMessage` with `TextContent` and a timestamp)\n",
    "- `AgentMessage`\n",
    "- `Sequence[AgentMessage]`\n",
    "\n",
    "Guardrails:\n",
    "- If `is_streaming` is `True`, `prompt` raises a `RuntimeError` (use `steer` or `follow_up` instead).\n",
    "- `continue_run` requires existing messages and the last message must not be an assistant message.\n",
    "- `continue_()` is an alias for backward compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8806a7e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ initialize ] default_model: {'provider': 'gemini', 'id': 'gemini-2.5-flash-lite', 'api': None}.\n"
     ]
    }
   ],
   "source": [
    "agent2 = Agent()\n",
    "agent2.set_model({\"provider\": \"gemini\", \"id\": None, \"api\": None})\n",
    "\n",
    "# Create a state where the last message is a user message.\n",
    "agent2.replace_messages([\n",
    "    AgentMessage(\n",
    "        role=\"user\",\n",
    "        content=[TextContent(type=\"text\", text=\"Continue from here.\")],\n",
    "        timestamp=time.time(),\n",
    "    )\n",
    "])\n",
    "\n",
    "await agent2.continue_run()\n",
    "for k, v in agent2._state.__dict__.items():\n",
    "    if k == \"messages\":\n",
    "        print(f\"{k}:\")\n",
    "        for m in v:\n",
    "            print(f\"  - {m.role}: {[c.text for c in m.content if isinstance(c, TextContent)]}\")\n",
    "        continue\n",
    "    print(f\"{k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c89598",
   "metadata": {},
   "source": [
    "## Abort, wait_for_idle, and reset\n",
    "\n",
    "- `abort()` sets an internal event that the loop checks to stop work.\n",
    "- `wait_for_idle()` awaits the internal idle flag to know when a run finishes.\n",
    "- `reset()` clears messages, streaming flags, pending tool calls, and queues.\n",
    "  It does not change system prompt, model, tools, session id, or other config.\n",
    "\n",
    "On exceptions inside `_run_loop`, `Agent` creates an assistant error message with:\n",
    "- `stop_reason = \"aborted\"` if the abort event was set, otherwise `\"error\"`\n",
    "- `error_message = str(exc)`\n",
    "This error message is appended to history and an `agent_end` event is emitted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e498bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage (safe to call even without a running stream)\n",
    "agent.reset()\n",
    "\n",
    "# If a long run is in progress:\n",
    "# agent.abort()\n",
    "# await agent.wait_for_idle()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
